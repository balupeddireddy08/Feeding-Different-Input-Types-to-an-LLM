{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "* A placeholder in Langchain is a variable or token within a prompt template that can be dynamically replaced with actual values at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"Translate the following text from English to {language}: {text}\"\n",
    "# Here, The placeholders are: {language}, {text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Feeding Input\n",
    "* String prompt composition\n",
    "* Chat prompt composition\n",
    "* Using PipelinePrompt\n",
    "* Example selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String PromptTemplates\n",
    "* String prompt templates are essentially placeholders within a text string that can be dynamically filled with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Hello, {name}! How are you today?\" # Greeting\n",
    "template = \"What is the capital of {country}?\" # Question\n",
    "\n",
    "# Instructions\n",
    "template = \"Translate the following text from English to {language}: {text}\" # Translations\n",
    "template = \"Write a product review for {product} targeting {audience}. Focus on {aspect}.\" # Product Review\n",
    "template = \"Write a short story about a {character} who {action} in a {setting}.\" # Story Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Large Language Model (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\balup\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\balup\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Set the Hugging Face Hub API token as an environment variable\n",
    "import os\n",
    "from secret_api_keys import huggingface_api_key\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_api_key\n",
    "\n",
    "# Import Hugging Face endpoint class\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(\n",
    "repo_id= 'mistralai/Mistral-Nemo-Instruct-2407',\n",
    "token = huggingface_api_key,\n",
    "temperature= 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "* Prompt templates help to translate user input and parameters into instructions for a language model. \n",
    "\n",
    "    * Input -> Dictionary\n",
    "    * Output -> PromptValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the prompt template\n",
    "\n",
    "#### Parameters\n",
    "* <b>template</b>: This is the core of the PromptTemplate. It's a string containing placeholders enclosed in curly braces {}\n",
    "* <b>input_variables</b>: A list of strings specifying the names of the placeholders in the template.\n",
    "* <b>output_parser</b>: (Optional) This attribute can be used to specify a parser that will process the output of the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"Translate the following text from English to {language}: {text}\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"language\", \"text\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output1: Translate the following text from English to Spanish: Hello, how are you?\n",
      "Output2: Translate the following text from English to French: I love to code.\n"
     ]
    }
   ],
   "source": [
    "# Using the prompt with different values, The format method replaces the placeholders with actual values.\n",
    "output1 = prompt.format(language=\"Spanish\", text=\"Hello, how are you?\")\n",
    "print(\"Output1:\", output1)\n",
    "output2 = prompt.format(language=\"French\", text=\"I love to code.\")\n",
    "print(\"Output2:\", output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I love the logic, the problem-solving, and the creativity that comes with it.\n",
      "\n",
      "Translation: J'aime coder. J'aime la logique, la résolution de problèmes et la créativité que cela implique.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "print(chain.invoke({\"language\":'French', \"text\":'I love to code.'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate.from_template\n",
    "\n",
    "* PromptTemplate.from_template is a convenient method in Langchain for quickly creating a PromptTemplate object from a given template string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"Translate the following text from English to {language}: {text}\"\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StringPromptTemplate\n",
    "\n",
    "<b>Note: Deprecated</b>\n",
    "* StringPromptTemplate is deprecated in the LangChain framework. \n",
    "* This change is part of ongoing updates to the LangChain library to improve its functionality and usability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "# prompt_template = \"Translate the following text from English to {language}: {text}\"\n",
    "# prompt = StringPromptTemplate(\n",
    "#     template=prompt_template,\n",
    "#     input_variables=[\"language\", \"text\"]\n",
    "# )\n",
    "\n",
    "# output = prompt.format(language=\"Spanish\", text=\"Hello, how are you?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String prompt composition\n",
    "* It is the process of combining multiple string-based prompts into a single, coherent prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a story about a brave knight who rescues a princess.\n"
     ]
    }
   ],
   "source": [
    "# Basic Composition\n",
    "# The simplest way to compose string prompts is by direct concatenation using the + operator.\n",
    "# Example: String Composition\n",
    "\n",
    "prompt1 = \"Write a story about a \"\n",
    "prompt2 = \"brave knight \"\n",
    "prompt3 = \"who rescues a princess.\"\n",
    "\n",
    "combined_prompt = prompt1 + prompt2 + prompt3\n",
    "print(combined_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short story about a brave knight who rescues in a magical forest.\n"
     ]
    }
   ],
   "source": [
    "# Example: PromptTemplate - Traditional way\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"Write a short story about a {character} who {action} in a {setting}.\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"character\", \"action\", \"setting\"])\n",
    "\n",
    "# Create different prompts by filling in the placeholders\n",
    "prompt1 = prompt.format(character=\"brave knight\", action=\"rescues\", setting=\"magical forest\")\n",
    "prompt2 = prompt.format(character=\"wise old wizard\", action=\"discovers\", setting=\"hidden cave\")\n",
    "print(prompt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A dragon is terrorizing a village and a knight must save them.\n",
      "\n",
      "Title: The Knight of the Whispering Woods\n",
      "\n",
      "In the heart of the mystical kingdom of Eldoria, where ancient magic still lingered, lay the enchanted forest of Elderglen. This was no ordinary forest; its trees were ancient and wise, their leaves whispering secrets in the wind, and its depths harbored creatures both wondrous and terrifying.\n",
      "\n",
      "The village of Meadowgrove nestled on the edge of Elderglen, its people living in harmony with the forest's magic. But their peaceful existence was shattered when a monstrous dragon, scales as black as night and eyes burning like embers, began to terrorize them. Villagers lived in fear, their once joyful lives now filled with dread.\n",
      "\n",
      "Among the villagers was a young blacksmith's apprentice named Elara. She was known for her fiery spirit and courage, her heart yearning for adventure. When the dragon took her best friend's younger sister, Elara knew she had to do something. She couldn't wait for a hero to save them; she had to be that hero herself.\n",
      "\n",
      "Elara sought the counsel of the village elder, who revealed an ancient prophecy: \"When the dragon's shadow falls, a knight of the forest shall rise, armed with courage and a heart pure as the first snow. Only they can defeat the dragon and restore peace to the land.\"\n",
      "\n",
      "With newfound determination, Elara ventured into Elderglen, seeking the knight destined to save Meadowgrove. She journeyed deep into the forest, guided by the whispers of the ancient trees. They led her to a hidden glade where a magnificent white stallion grazed, untethered and wild. The horse snorted softly, its eyes filled with intelligence and understanding.\n",
      "\n",
      "Elara approached the stallion, her heart pounding. She reached out a tentative hand, and the horse nuzzled it gently. A surge of warmth and strength flowed through her, and she knew this was her destiny. She climbed onto the horse's back, and together, they rode towards the dragon's lair.\n",
      "\n",
      "As they journeyed deeper into the forest, Elara found a suit of gleaming armor lying across a fallen tree. It shimmered in the dappled sunlight, and as she put it on, it fit her perfectly, as if made just for her. She felt invincible, her courage growing with each step.\n",
      "\n",
      "Finally, they reached the dragon's lair, a cave carved\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "print(chain.invoke({'character':\"brave knight\", 'action':\"rescues\", 'setting':\"magical forest\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a story about brave knight who rescues in a magical forest.\n"
     ]
    }
   ],
   "source": [
    "# Combining String Composition and PromptTemplate\n",
    "\n",
    "base_prompt = \"Write a story\"\n",
    "template = \" about {character} who {action} in a {setting}.\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"character\", \"action\", \"setting\"])\n",
    "\n",
    "combined_prompt = base_prompt + prompt.format(character=\"brave knight\", action=\"rescues\", setting=\"magical forest\")\n",
    "print(combined_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'topic'], template='Tell me a joke about {topic}, make it funny\\n\\nand in {language}')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining String Composition and PromptTemplate\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = (\n",
    "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "    + \", make it funny\"\n",
    "    + \"\\n\\nand in {language}\"\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke about sports, make it funny\\n\\nand in spanish'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(topic=\"sports\", language=\"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Formatting of Prompt Templates\n",
    "* It allows us to fill in some variables within a prompt template while leaving others for later specification. \n",
    "\n",
    "LangChain supports this in two ways:\n",
    "\n",
    "1. Partial formatting with string values.\n",
    "2. Partial formatting with functions that return string values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial with strings\n",
    "* <b>For example</b>, suppose you have a prompt template for generating social media posts that requires a product name and a target audience. \n",
    "* You might know the product name upfront but need to determine the target audience later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prompt: input_variables=['audience', 'product'] template='Create a social media post promoting a {product} to {audience}.'\n",
      "Partial Prompt: input_variables=['audience'] partial_variables={'product': 'New Smartphone'} template='Create a social media post promoting a {product} to {audience}.'\n",
      "Total Prompt:  Create a social media post promoting a New Smartphone to tech enthusiasts.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Create a social media post promoting a {product} to {audience}.\")\n",
    "print('Initial Prompt:', prompt)\n",
    "partial_prompt = prompt.partial(product=\"New Smartphone\")\n",
    "print('Partial Prompt:', partial_prompt)\n",
    "total_prompt = partial_prompt.format(audience=\"tech enthusiasts\")\n",
    "print(\"Total Prompt: \", total_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial with functions\n",
    "* The use case for this is when you have a variable you know that you always want to fetch in a common way. A prime example of this is with date or time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about the day 08/03/2024, 10:59:56\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def _get_datetime():\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Tell me a {adjective} joke about the day {date}\",\n",
    "    input_variables=[\"adjective\", \"date\"],\n",
    ")\n",
    "partial_prompt = prompt.partial(date=_get_datetime)\n",
    "print(partial_prompt.format(adjective=\"funny\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UTC. Why is this a joke?\n",
      "\n",
      "Why did the calendar go to therapy on 08/03/2024 at 11:00:10 UTC? It had too many dates!\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(partial_prompt.format(adjective=\"funny\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
